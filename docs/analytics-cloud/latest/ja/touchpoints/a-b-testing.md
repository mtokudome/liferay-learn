# A/Bテスト

A/Bテストでは、ページの複数のバージョン/レイアウトを一度にテストすることで、コンテンツページの有効性を評価します。 これは、オリジナルページのページバリアントを作成し、目標（クリック数など）を持ってページをテストし、最も効果的なバリアントを公開することで行われます。 A/Bテストの作成とコンテンツページの設定については、Liferay DXPの [A/Bテストのドキュメント](https://help.liferay.com/hc/en-us/articles/360034856751-A-B-Testing) を参照してください。

Liferay DXPで実行されているA/Bテストの結果はすべて、Analytics Cloudによって追跡されます。 A/Bテストは、作成されるとAnalytics Cloudと同期されます。 そこから、Analytics CloudからA/Bテストの管理を行うことができます。 下書きされたテスト、実行中のテスト、終了したテスト、完了したA/Bテストをすべて表示するには、左の列からTestsメニューに移動します。

![テストメニューには、サイトのために作成・定義されたすべてのA/Bテストが表示されます。](a-b-testing/images/01.png)

ドラフトされたA/Bテストの場合、以下のような管理が可能です。

  - *ターゲット：* エクスペリエンスとユーザーセグメント
  - *メトリクス：* 追跡する目標（バウンス率やクリック率など）。
  - *バリアント：* ユーザーが対話するためのページのバリアント。
  - *トラフィックの分割：* ページを訪問するときに、ランダムにバリアント間で分割される訪問者の割合。
  - *信頼度：* 検査結果の精度。

![A/Bテストの設定作業。](a-b-testing/images/02.png)

A/Bテストのセットアップの詳細については、Liferay DXPのA/Bテストのドキュメントを参照してください。

A/Bテストが実行されると、Analytics Cloudには、A/Bテストの進捗状況を最新の状態に保つためのレポートがいくつか用意されています。

  - *サマリー*
  - *バリアントレポート*
  - *テストセッション*

## サマリー

サマリーパネルでは、テストの概要を確認することができます。 以下のような情報を提供してくれます。

  - *完成度*
  - *実行時間（日数）*
  - *総訪問者数*

また、テスト・メトリクスと現在の最高のパフォーマンスを発揮しているバリアントを簡単に見ることができます。

![](a-b-testing/images/03.png)

## バリアントレポート

バリアントレポートパネルでは、各バリアントの詳細な内訳とそのパフォーマンスを確認できます。

![](a-b-testing/images/04.png)

以下は、各バリアントについて報告されたメトリクスです。

**中央値：** サンプル値の集合内の中間値。 これは、典型的なユーザーの行動を推定します。

**信頼区間：** 母集団の真の平均を含むと期待される値の範囲。 例えば、95信頼区間とは、システムが真の平均値を含むことを95%確信している値の範囲のことです。 これは、測定された目標に対してもっともらしいと思われる値の範囲を与えます。

**改善：** 対照群からの相対的な改善。 このメトリックは、リフトとしても知られています。 例えば、コントロールページの保持率が15％だとします。 改善の計算は、 `((16 - 15) / 15) = ~6.67%` 改善となります。

変化の影響を知ることができます。 わずかな改善しかないのであれば、その変更を実施する価値はないかもしれません。

**勝率：** は、そのバリアントが他のすべての参加バリアントを打ち負かす可能性を予測します。 これにより、複数のメトリクスがどのように比較されているかを確認することができます。 例えば、競馬イベントを考えてみましょう：各馬は、レースの数千回のレースをシミュレートすることによって計算されたレース（すなわち、勝利のオッズ）の前に掲載されている勝つために生成されたチャンスを持っています。 この方法は、A/Bテストに勝つ確率を計算するために、バリアントにも同じ方法を使用します。

**ユニークビジター：** バリアントに貢献している訪問者の数。 ランダムにバリアントを割り当てられた訪問者は、テストが終了するまで常に同じバリアントを見ています。

ページにヒットしているトラフィックの量を知るだけでなく、この指標は、A/Bテストの構成方法に問題があるかどうかを判断するのにも役立ちます。 例えば、ある Variant に行くトラフィックが多すぎる可能性があります (通常、Segment の設定ミスが原因です)。

## テストセッション

テストセッション] パネルには、1日あたりのテストインプレッションの閲覧セッション数を示す統計情報が表示されます。 これにより、オーディエンスがA/Bテストのインプレッションに誘導されていることを確認することができます。 また、あなたのテストが、以前と比べてページへのトラフィックにどのような影響を与えるかを示しています。

![](a-b-testing/images/05.png)

次に、A/Bテストのステータスについてです。

## テストステータス

A/Bテストは、開始後に必ずステータスが付いているのが特徴です。 これらには以下のものが含まれます。

  - *テストが実行されている*
  - *勝者が宣言されました*
  - *クリア勝者なし*

次はそれぞれのステータスを探っていくことになります。

### テストが実行されている

これは、あなたのテストはまだ実行中であり、勝者を宣言する前に、より大きなサンプルサイズが必要であることを意味します。 どのVariantがあなたの現在のベストであるかを見ることができますが、希望する信頼度が満たされていません。

![](a-b-testing/images/06.png)

テストが実行されているときは、サマリーバーから［Terminate］を選択することで、テストを終了することができます。

![](a-b-testing/images/07.png)

### ウィンダーは宣言した

A/Bテストが正常に終了すると、バリアントが勝者と宣言されます。 この状態では、以下の動作を行うことができます。

  - 勝利した Variant をデフォルトのエクスペリエンスとして公開します。
  - Variantsを公開せずにテストを完了させてください。

![](a-b-testing/images/08.png)

### クリア勝者なし

コントロール ページを大幅に上回ったバリエーションがないため、Analytics Cloudでは勝者を決定できないことがあります。 この場合、何も公開せずにテストを完了させることができます。 コントロールはデフォルトのままです。

![](a-b-testing/images/09.png)

A/Bテスト用に生成された分析結果を表示することで、A/Bテストの進捗状況を常に把握することができます。 提供されたデータがあれば、自信を持ってサイトのユーザーに最適なエクスペリエンスを選択することができます。
